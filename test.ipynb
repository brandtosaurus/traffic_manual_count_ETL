{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MB2705851\\AppData\\Local\\Temp\\ipykernel_12932\\2559507519.py:44: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import config\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import calcs\n",
    "import config\n",
    "\n",
    "import main\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "DROP_IF = [\"DO NOT FILL IN\", \"DO NOT F\"]\n",
    "\n",
    "\n",
    "# ENGINE = create_engine(\n",
    "#     r\"postgresql://postgres:$admin@localhost:5432/asset_management_master\"\n",
    "# )\n",
    "\n",
    "# ENGINE = create_engine(\n",
    "#     r\"postgresql://postgres:$admin@localhost:5432/asset_management_master\"\n",
    "# )\n",
    "\n",
    "TYPE = \"Detailed Manual Traffic Count Form\"\n",
    "\n",
    "DROP_IF = [\"DO NOT FILL IN\", \"DO NOT F\"]\n",
    "\n",
    "PATH = r\"C:\\Users\\MB2705851\\Desktop\\Temp\\manual_traffic_counts\\2022-04-06\"\n",
    "PATH2 = r\"C:\\Users\\MB2705851\\OneDrive - Surbana Jurong Private Limited\\Manuals & Guidelines\\Traffic\\Manual count import templates\\Flat Template.xlsx\"\n",
    "PATH3 = r\"C:\\Users\\MB2705851\\Desktop\\Temp\\manual_traffic_counts\\TEST\\216A-190905.xlsx\"\n",
    "OUTPATH = r\"C:\\Users\\MB2705851\\Desktop\\Temp\\Temp Excel\\TEST.csv\"\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfiles(path) -> List[str]:\n",
    "    print(\"COLLECTING FILES......\")\n",
    "    src = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if name.endswith(\".xlsx\") or name.endswith(\".csv\"):\n",
    "                p = os.path.join(root, name)\n",
    "                src.append(p)\n",
    "    src = list(set(src))\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLECTING FILES......\n"
     ]
    }
   ],
   "source": [
    "files = getfiles(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completed_files():\n",
    "    completed_list = []\n",
    "    with open(r\"C:\\Users\\MB2705851\\Desktop\\Temp\\manual_traffic_counts\\COMPLETED_FILES.csv\", \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            completed_list.append(row[0])\n",
    "    return completed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_etl(df, file) -> pd.DataFrame:\n",
    "\n",
    "    ## UNCOMMENT THIS WHEN WORKING WITH FILES\n",
    "    # xls = pd.ExcelFile(file)\n",
    "    # df = pd.read_excel(file, sheet_name=xls.sheet_names, header=None)\n",
    "    # for key, df in df.items():\n",
    "    \n",
    "    header = {\n",
    "        \"header_id\": [str(uuid.uuid4())],\n",
    "        \"document_url\": file,\n",
    "        \"counted_by\": [\"CKDM\"],\n",
    "        \"tc_station_name\": [df.loc[0, 1]],\n",
    "        \"count_type_id\": 3,\n",
    "        \"count_date_start\": [df.loc[1, 1]],\n",
    "        \"count_weather\": [df.loc[2, 1]],\n",
    "        \"h_station_date\": [df.loc[0, 1] + \"_\" + str(df.loc[1, 1])],\n",
    "        \"growth_rate_use\": [str(\"y\")],\n",
    "        \"count_interval\": [60],\n",
    "    }\n",
    "    header_temp = pd.DataFrame(header)\n",
    "    self.header_out_df = self.header_out_df.merge(header_temp, how=\"outer\")\n",
    "    # self.header_out_df = self.header_out_df.drop_duplicates()\n",
    "\n",
    "    data = df.loc[6:24, 0:5]\n",
    "    data.dropna(thresh=5)\n",
    "    data.rename(\n",
    "        columns={\n",
    "            0: \"count_hour\",\n",
    "            1: \"light\",\n",
    "            2: \"heavy\",\n",
    "            3: \"bus\",\n",
    "            4: \"taxi\",\n",
    "            5: \"total\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    data = data[data.count_hour.isin(DROP_IF) == False]\n",
    "\n",
    "    data[\"header_id\"] = header_temp.loc[0, \"header_id\"]\n",
    "\n",
    "    data[\"count_hour\"] = pd.to_datetime(\n",
    "        data[\"count_hour\"].str[:8], format=\"%H:%M:%S\"\n",
    "    ).dt.time\n",
    "\n",
    "    hour = data[\"count_hour\"].astype(str)\n",
    "    data[\"count_time\"] = header_temp.loc[0, \"count_date_start\"]\n",
    "    data[\"count_time\"] = pd.to_datetime(\n",
    "        data[\"count_time\"], format=\"%y/%m/%d\"\n",
    "    ) + pd.to_timedelta(hour)\n",
    "\n",
    "    data[\"header_date\"] = header_temp.loc[0, \"count_date_start\"]\n",
    "\n",
    "    data = check_if_calculated(data)\n",
    "    data_out_df = data_out_df.merge(data, how=\"outer\")\n",
    "    data_out_df = data_out_df.drop_duplicates()\n",
    "\n",
    "def etl_no_veryheavy( df, file) -> pd.DataFrame:\n",
    "\n",
    "    ## UNCOMMENT THIS WHEN WORKING WITH FILES\n",
    "    # xls = pd.ExcelFile(file)\n",
    "    # df = pd.read_excel(file, sheet_name=xls.sheet_names, header=None)\n",
    "    # for key, df in df.items():\n",
    "\n",
    "    try:\n",
    "\n",
    "        if pd.isnull(df.loc[23, 8]):\n",
    "            weather = \"sunny\"\n",
    "        else:\n",
    "            weather = df.loc[23, 8]\n",
    "\n",
    "        gid = str(uuid.uuid4())\n",
    "\n",
    "        header = {\n",
    "            \"header_id\": [gid],\n",
    "            \"document_url\": file,\n",
    "            \"counted_by\": [df.loc[16, 8]],\n",
    "            \"tc_station_name\": [str(df.loc[4, 8]) + str(df.loc[5, 8])],\n",
    "            \"count_type_id\": 3,\n",
    "            \"count_date_start\": [df.loc[2, 1]],\n",
    "            \"count_weather\": [weather],\n",
    "            \"h_station_date\": [gid],\n",
    "            # [\n",
    "            #     str(df.loc[4, 8]) + str(df.loc[5, 8]) + \"_\" + str(df.loc[2, 1])\n",
    "            # ],\n",
    "            \"growth_rate_use\": [str(\"Y\")],\n",
    "            \"count_interval\": [60],\n",
    "            \"latitude\": [df.loc[14, 8]],\n",
    "            \"longitude\": [df.loc[15, 8]],\n",
    "            \"kilometer_dist\": [df.loc[8, 8]],\n",
    "            \"road_link\": [df.loc[6, 8]],\n",
    "            \"type_of_count\": [df.loc[13, 8]],\n",
    "            \"description\": [\n",
    "                \"Between \" + str(df.loc[9, 8]) + \" and \" + str(df.loc[10, 8])\n",
    "            ],\n",
    "            \"count_duration_hours\": [df.loc[24, 8]],\n",
    "            \"no_days\": [df.loc[25, 8]],\n",
    "        }\n",
    "        header_temp = pd.DataFrame(header)\n",
    "\n",
    "        data = df.loc[4:29, 0:5]\n",
    "        data = data[(data[0] != \"Subtotal A\") & (data[0] != \"Subtotal B\")]\n",
    "        data = data.dropna(thresh=5)\n",
    "        data.rename(\n",
    "            columns={\n",
    "                0: \"count_hour\",\n",
    "                1: \"light\",\n",
    "                2: \"heavy\",\n",
    "                3: \"bus\",\n",
    "                4: \"taxi\",\n",
    "                5: \"total\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        data[\"count_hour\"] = data[\"count_hour\"].str[:2]\n",
    "        data[\"h_station_date\"] = header_temp.loc[0, \"h_station_date\"]\n",
    "        data[\"tcname\"] = header_temp.loc[0, \"tc_station_name\"]\n",
    "\n",
    "        # data[\"count_hour\"] = pd.to_datetime(\n",
    "        #     data[\"count_hour\"].str[:8], format=\"%H\"\n",
    "        # ).dt.time\n",
    "\n",
    "        hour = data[\"count_hour\"].astype(str)\n",
    "        data[\"count_time\"] = header_temp.loc[0, \"count_date_start\"]\n",
    "        data[\"count_time\"] = pd.to_datetime(\n",
    "            data[\"count_time\"], format=\"%y/%m/%d\"\n",
    "        ) + pd.to_timedelta(hour)\n",
    "\n",
    "        data[\"header_date\"] = header_temp.loc[0, \"count_date_start\"]\n",
    "\n",
    "        new_datetime = (\n",
    "            header_temp.loc[0, \"count_date_start\"].strftime(\"%Y-%m-%d\") + \" \" + hour\n",
    "        )\n",
    "        data[\"count_hour\"] = pd.to_datetime(new_datetime)\n",
    "\n",
    "        data = check_if_calculated(data)\n",
    "\n",
    "        header_temp[\"count_duration_hours\"] = data[\"total\"].notnull().sum()\n",
    "        if header_temp[\"count_duration_hours\"].any() == 18:\n",
    "            data[\"count_type_id\"] = 4\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        header_out_df = header_out_df.merge(header_temp, how=\"outer\")\n",
    "        data_out_df = data_out_df.merge(data, how=\"outer\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"something wrong with the NO VERY HEAVY PROCESS\" + e)\n",
    "        with open(\n",
    "            os.path.expanduser(config.PROBLEM_FILES),\n",
    "            \"a\",\n",
    "            newline=\"\",\n",
    "        ) as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerows([[file]])\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(df, file, type, key):\n",
    "    if type == \"Basic Format\":\n",
    "        print(\"calculating using cumulative_etl\")\n",
    "        # cumulative_etl(df, file)\n",
    "    elif (type == \"Manual Traffic Counting Sheet\") and (\n",
    "        df.loc[3, 5] == \"Total\"\n",
    "    ):\n",
    "        print(\"calculating using etl_no_veryheavy\")\n",
    "        # etl_no_veryheavy(df, file)\n",
    "    elif (type == \"Manual Traffic Counting Sheet\") and (\n",
    "        df.loc[3, 6] == \"Total\"\n",
    "    ):\n",
    "        print(\"calculating using etl_template_form\")\n",
    "        etl_template_form(df, file)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_count_calc(df):\n",
    "    df2 = df\n",
    "    df[\"light\"] = df[\"light\"].diff().fillna(df[\"light\"])\n",
    "    df[\"heavy\"] = df[\"heavy\"].diff().fillna(df[\"heavy\"])\n",
    "    df[\"bus\"] = df[\"bus\"].diff().fillna(df[\"bus\"])\n",
    "    df[\"taxi\"] = df[\"taxi\"].diff().fillna(df[\"taxi\"])\n",
    "    df[\"total\"] = df[\"total\"].diff().fillna(df[\"total\"])\n",
    "    if (df.values < 0).any():\n",
    "        return df2\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_calculated(data):\n",
    "    # print(\"checking if calculated\")\n",
    "    a = pd.Series(data[\"total\"])\n",
    "    amin = a.min()\n",
    "    avg = a.max() - amin\n",
    "    if avg == 0:\n",
    "        return data\n",
    "    else:\n",
    "        normalized_df = (a - amin) / avg\n",
    "        l = []\n",
    "        cnt = a.count()\n",
    "        for i in range(cnt):\n",
    "            if i == 0:\n",
    "                l.append(True)\n",
    "            elif (a.iloc[i] >= a.iloc[i-1]):\n",
    "                l.append(True)\n",
    "            else:\n",
    "                l.append(False)\n",
    "        if ((normalized_df.iloc[0] == 0) & (normalized_df.iloc[-1] == 1)) and all(element == True for element in l):\n",
    "            return hourly_count_calc(data)\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def etl_template_form(df, file) -> pd.DataFrame:\n",
    "    # print(\"processing etl_template_form\")\n",
    "## UNCOMMENT THIS WHEN WORKING WITH FILES\n",
    "# xls = pd.ExcelFile(file)\n",
    "# df = pd.read_excel(file, sheet_name=xls.sheet_names, header=None)\n",
    "# for key, df in df.items():\n",
    "\n",
    "    if pd.isnull(df.loc[23, 9]):\n",
    "        weather = \"sunny\"\n",
    "    else:\n",
    "        weather = df.loc[23, 9]\n",
    "\n",
    "    gid = str(uuid.uuid4())\n",
    "\n",
    "    header = {\n",
    "        \"header_id\": [gid],\n",
    "        \"document_url\": file,\n",
    "        \"counted_by\": [df.loc[16, 9]],\n",
    "        \"tc_station_name\": [str(df.loc[4, 9]) + str(df.loc[5, 9])],\n",
    "        \"count_type_id\": 3,\n",
    "        \"count_date_start\": [df.loc[2, 1]],\n",
    "        \"count_weather\": [weather],\n",
    "        \"h_station_date\": [gid],\n",
    "        # [\n",
    "        #     str(df.loc[4, 8]) + str(df.loc[5, 8]) + \"_\" + str(df.loc[2, 1])\n",
    "        # ],\n",
    "        \"growth_rate_use\": [str(\"Y\")],\n",
    "        \"count_interval\": [60],\n",
    "        \"latitude\": [df.loc[14, 9]],\n",
    "        \"longitude\": [df.loc[15, 9]],\n",
    "        \"kilometer_dist\": [df.loc[8, 9]],\n",
    "        \"road_link\": [df.loc[6, 9]],\n",
    "        \"type_of_count\": [df.loc[13, 9]],\n",
    "        \"description\": [\n",
    "            \"Between \" + str(df.loc[9, 9]) + \" and \" + str(df.loc[10, 9])\n",
    "        ],\n",
    "        \"count_duration_hours\": [df.loc[24, 9]],\n",
    "        \"no_days\": [df.loc[25, 9]],\n",
    "    }\n",
    "    header_temp = pd.DataFrame(header)\n",
    "\n",
    "    data = df.loc[4:29, 0:6]\n",
    "    data = data[(data[0] != \"Subtotal A\") & (data[0] != \"Subtotal B\")]\n",
    "    data = data.dropna(thresh=5)\n",
    "    data.rename(\n",
    "        columns={\n",
    "            0: \"count_hour\",\n",
    "            1: \"light\",\n",
    "            2: \"heavy\",\n",
    "            3: \"veryheavy\",\n",
    "            4: \"bus\",\n",
    "            5: \"taxi\",\n",
    "            6: \"total\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    data[\"count_hour\"] = data[\"count_hour\"].str[:2]\n",
    "    data[\"h_station_date\"] = header_temp.loc[0, \"h_station_date\"]\n",
    "    data[\"tcname\"] = header_temp.loc[0, \"tc_station_name\"]\n",
    "\n",
    "    # data[\"count_hour\"] = pd.to_datetime(\n",
    "    #     data[\"count_hour\"].str[:8], format=\"%H\"\n",
    "    # ).dt.time\n",
    "\n",
    "    hour = data[\"count_hour\"].astype(str)\n",
    "    data[\"count_time\"] = header_temp.loc[0, \"count_date_start\"]\n",
    "    data[\"count_time\"] = pd.to_datetime(\n",
    "        data[\"count_time\"], format=\"%y/%m/%d\"\n",
    "    ) + pd.to_timedelta(hour)\n",
    "\n",
    "    data[\"header_date\"] = header_temp.loc[0, \"count_date_start\"]\n",
    "\n",
    "    new_datetime = (\n",
    "        header_temp.loc[0, \"count_date_start\"].strftime(\"%Y-%m-%d\") + \" \" + hour\n",
    "    )\n",
    "    data[\"count_hour\"] = pd.to_datetime(new_datetime)\n",
    "\n",
    "    data = check_if_calculated(data)\n",
    "\n",
    "    header_temp[\"count_duration_hours\"] = data[\"total\"].notnull().sum()\n",
    "    if header_temp[\"count_duration_hours\"].any() == 18:\n",
    "        data[\"count_type_id\"] = 4\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # header_out_df = header_out_df.merge(header_temp, how=\"outer\")\n",
    "    # data_out_df = data_out_df.merge(data, how=\"outer\")\n",
    "    return header_temp, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "C:\\Users\\MB2705851\\Desktop\\Temp\\manual_traffic_counts\\2022-04-06\\774.xlsxSheet4\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "5\n",
      "C:\\Users\\MB2705851\\Desktop\\Temp\\manual_traffic_counts\\2022-04-06\\774.xlsxSheet5\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "header_out_df = pd.DataFrame(columns=config.HEADER)\n",
    "data_out_df = pd.DataFrame(columns=config.DATA)\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_excel(file, sheet_name=None, header=None,)\n",
    "    type = \"Manual Traffic Counting Sheet\"\n",
    "    for key, df in df.items():\n",
    "        l = get_completed_files()\n",
    "        if file + '-' + key in l:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "\n",
    "                if type == \"Basic Format\":\n",
    "                    # print(\"calculating using cumulative_etl\")\n",
    "                    cumulative_etl(df, file)\n",
    "                elif (type == \"Manual Traffic Counting Sheet\") and (\n",
    "                    df.loc[3, 5] == \"Total\"\n",
    "                ):\n",
    "                    # print(\"calculating using etl_no_veryheavy\")\n",
    "                    etl_no_veryheavy(df, file)\n",
    "                elif (type == \"Manual Traffic Counting Sheet\") and (\n",
    "                    df.loc[3, 6] == \"Total\"\n",
    "                ):\n",
    "                    # print(\"calculating using etl_template_form\")\n",
    "                    header, data = etl_template_form(df, file)\n",
    "                    header_out_df = pd.concat([header_out_df,header], join='outer', axis=0, ignore_index=True)\n",
    "                    data_out_df = pd.concat([data_out_df,data], join='outer' , axis=0, ignore_index=True)\n",
    "                else:\n",
    "                    print(\"choosing something else\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(file + key)\n",
    "                print(df)\n",
    "\n",
    "header_out_df = header_out_df.dropna(axis=1, how = 'all')\n",
    "data_out_df = data_out_df.dropna(axis=1, how = 'all')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_out_df = header_out_df.drop_duplicates()\n",
    "data_out_df = data_out_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count_hour light heavy veryheavy  bus taxi total  \\\n",
      "0  2022-02-15 06:00:00  1119  20    18        156  21   1334   \n",
      "1  2022-02-15 07:00:00  872   24    19        122  7    1044   \n",
      "2  2022-02-15 08:00:00  618   28    18        88   8    760    \n",
      "3  2022-02-15 09:00:00  710   28    23        87   8    856    \n",
      "4  2022-02-15 10:00:00  653   69    30        70   0    822    \n",
      "\n",
      "           header_date                     count_time  \\\n",
      "0  2022-02-15 00:00:00  2022-02-15 00:00:00.000000006   \n",
      "1  2022-02-15 00:00:00  2022-02-15 00:00:00.000000007   \n",
      "2  2022-02-15 00:00:00  2022-02-15 00:00:00.000000008   \n",
      "3  2022-02-15 00:00:00  2022-02-15 00:00:00.000000009   \n",
      "4  2022-02-15 00:00:00  2022-02-15 00:00:00.000000010   \n",
      "\n",
      "                         h_station_date tcname  \n",
      "0  88645bb3-78ab-4cda-a96c-846e0d29c926  127A   \n",
      "1  88645bb3-78ab-4cda-a96c-846e0d29c926  127A   \n",
      "2  88645bb3-78ab-4cda-a96c-846e0d29c926  127A   \n",
      "3  88645bb3-78ab-4cda-a96c-846e0d29c926  127A   \n",
      "4  88645bb3-78ab-4cda-a96c-846e0d29c926  127A   \n"
     ]
    }
   ],
   "source": [
    "print(data_out_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(header_out_df, data_out_df):\n",
    "\n",
    "    csv_export = True\n",
    "\n",
    "    header_out_df = header_out_df.drop(\n",
    "            columns=[\n",
    "                \"header_id\",\n",
    "                \"latitude\",\n",
    "                \"longitude\",\n",
    "                \"kilometer_dist\",\n",
    "                \"road_link\",\n",
    "                \"type_of_count\",\n",
    "                \"description\",\n",
    "                \"no_days\",\n",
    "            ], errors='ignore'\n",
    "        )\n",
    "\n",
    "    data_out_df = data_out_df.drop(\n",
    "        columns=[\"header_date\", \"count_time\", \"header_id\"], errors='ignore'\n",
    "    )\n",
    "    if csv_export == True:\n",
    "        try:\n",
    "            # EXPORT AS CSV\n",
    "            header_out_df.to_csv(config.HEADEROUT, mode=\"a\", index=False)\n",
    "            print(\"CSV HEADER DONE\")\n",
    "        except Exception:\n",
    "            print(\"\"\"something went wrong with the HEADER CSV EXPORT\"\"\")\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            data_out_df.to_csv(config.DATAOUT, mode=\"a\", index=False)\n",
    "            print(\"CSV DATA DONE\")\n",
    "        except Exception:\n",
    "            print(\"\"\"something went wrong with the DATA CSV EXPORT\"\"\")\n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV HEADER DONE\n",
      "CSV DATA DONE\n"
     ]
    }
   ],
   "source": [
    "export(header_out_df, data_out_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f0240ba5a37eeffe7d380595dcf16248afe1beab2227011f0d1b1f050a1a57d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
